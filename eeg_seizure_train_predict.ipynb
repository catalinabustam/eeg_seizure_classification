{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "eeg_seizure_train_predict.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zmfz6lRpV3UW",
        "colab_type": "text"
      },
      "source": [
        "## UPenn and Mayo Clinic's Seizure Detection Challenge\n",
        "https://www.kaggle.com/c/seizure-detection/data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "alZdmHfVWFFH",
        "colab_type": "text"
      },
      "source": [
        "# Data set description: \n",
        "\n",
        "* 8 Patients\n",
        "\n",
        "* 4 Dogs\n",
        "\n",
        "For Each subject \n",
        "  * Different numbers of channels \n",
        "  * Different sampling rates from 500 Hz to 5,000 Hz\n",
        "  * Different number of samples\n",
        "\n",
        "\n",
        "Each data set consists of\n",
        "\n",
        "  * 1-second EEG clips labeled \"Ictal\" for seizure data segments, or \"Interictal\" for non-seizure data segments\n",
        "\n",
        "  * matrix of EEG sample values arranged  as [n_channel, n_time_points]\n",
        "  \n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGE_-fKQW-RC",
        "colab_type": "text"
      },
      "source": [
        "# Before run this notebook data set must be downloaded on a google drive folder\n",
        "Run before: *Download_visualize_data.ipynb*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRekvcY8Vurl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import os\n",
        "import glob\n",
        "import re\n",
        "from scipy.io import loadmat\n",
        "from scipy.signal import resample\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from sklearn import metrics\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6ai0EvyXgIH",
        "colab_type": "text"
      },
      "source": [
        "# Load folder where files are stored:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdkGsvClV2sT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        },
        "outputId": "c2aab2ee-9ecc-4e03-bb3f-15dc27d32876"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QymfNJixXomY",
        "colab_type": "text"
      },
      "source": [
        "# List all files in folder for each subject"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsNnV9KMamOa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def file_list(folder_path, output=False):\n",
        "    \n",
        "    file_list = []\n",
        "   \n",
        "    for filename in glob.glob(folder_path):\n",
        "        file_list.append(filename)\n",
        "        \n",
        "    file_list.sort()\n",
        "    \n",
        "    if output:\n",
        "        print(str(len(file_list)) + \" files found\")\n",
        "        pp.pprint(file_list)\n",
        "    \n",
        "    return file_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3M4C5u67fL-U",
        "colab_type": "text"
      },
      "source": [
        "# Load sample data to check how it looks\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysiJ-E84fcke",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ictal_list, interictal_list = get_data('Patient_1')\n",
        "first_ictal_file = ictal_list[1]\n",
        "first_interictal_file = interictal_list[1]\n",
        "\n",
        "print('Ictal')\n",
        "upenn_seizure_df, upenn_seizure_freq = mat_to_df(first_ictal_file, output=True)\n",
        "print('Interictal')\n",
        "upenn_baseline_df, upenn_baseline_freq = mat_to_df(first_interictal_file, output=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BG1yOMLxd0IC",
        "colab_type": "text"
      },
      "source": [
        "# Use mne library to visualize data, data is needed to be loaded as dataframe\n",
        "\n",
        "from: https://github.com/Eldave93/Seizure-Detection-Tutorials"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWT0bbLLdx_9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mat_to_df(file_path, output = False):\n",
        "  mat = loadmat(file_path)    # load mat-file\n",
        "\n",
        "  data = mat['data']          # variable in mat file\n",
        "  channels = mat['channels']  # dtypes of structures are \"unsized objects\"\n",
        "  freq = mat['freq'][0]\n",
        "\n",
        "  channels_list = []\n",
        "  for channel_array in channels[0][0]:\n",
        "    channels_list.append(channel_array[0])\n",
        "\n",
        "  df = pd.DataFrame(data,\n",
        "                    index=channels_list)\n",
        "\n",
        "  df = df.T\n",
        "\n",
        "  # remove columns that do not change value\n",
        "  df = df.loc[:, (df != df.iloc[0]).any()]\n",
        "\n",
        "  if output:\n",
        "    display(df.head())\n",
        "\n",
        "  return df, freq"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlG_DQbefpoc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mne.set_log_level('WARNING')\n",
        "\n",
        "def mne_object(data, freq):\n",
        "\n",
        "  info = mne.create_info(ch_names=list(data.columns), \n",
        "                         sfreq=freq, \n",
        "                         ch_types=['eeg']*data.shape[-1])\n",
        "  \n",
        "  # data needs to be in volts rather than in microvolts\n",
        "  data = data.apply(lambda x: x*1e-6)\n",
        "  # transpose the data\n",
        "  data_T = data.transpose()\n",
        "  \n",
        "  # create raw mne object\n",
        "  raw = mne.io.RawArray(data_T, info)\n",
        "  raw_tmp = raw.copy()\n",
        "  raw_tmp.filter(1, 70)\n",
        "\n",
        "  return raw, raw_tmp\n",
        "\n",
        "\n",
        "plot_kwargs = {\n",
        "    'scalings': dict(eeg=20e-5),   # zooms the plot out\n",
        "    'highpass': 0.5,              # filters out low frequencies\n",
        "    'lowpass': 70.,                # filters out high frequencies\n",
        "    'show_scrollbars': False,\n",
        "    'show': True\n",
        "}\n",
        "\n",
        "print('Interictal')\n",
        "upenn_baseline_mne, upp_filt= mne_object(upenn_baseline_df, upenn_baseline_freq)\n",
        "upenn_baseline_mne.plot(**plot_kwargs);\n",
        "print()\n",
        "print('Ictal')\n",
        "upenn_seizure_mne , sei_filt = mne_object(upenn_seizure_df, upenn_seizure_freq)\n",
        "upenn_seizure_mne.plot(**plot_kwargs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LnJrxTaTXy41",
        "colab_type": "text"
      },
      "source": [
        "# Read dataset names and create ictal and interictal lists"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KP-2pYPfV3ri",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_data(subject):\n",
        "\n",
        "  ictal_list = []\n",
        "  interictal_list = []\n",
        "\n",
        "\n",
        "  data_dir = os.path.join(os.getcwd(), 'drive','My Drive','deep_learning','eeg','Volumes', 'Seagate', \n",
        "                            'seizure_detection', 'competition_data', \n",
        "                            'clips', subject)\n",
        "  \n",
        "  all_list = file_list(os.path.join(data_dir, '*'), output=False)\n",
        "\n",
        "  for file in all_list:\n",
        "    if re.findall('interictal', file):\n",
        "      ictal_list.append(file)\n",
        "    elif re.findall('ictal', file):\n",
        "      interictal_list.append(file)\n",
        "  return ictal_list, interictal_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "czZATuk3YDDd",
        "colab_type": "text"
      },
      "source": [
        "# Load *mat* files standirize and resample to avoid memory problems"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AzxrH877WrWv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def parse_input_data(data_list, data_type):\n",
        "  y_value = (data_type == 'ictal')*1\n",
        "\n",
        "  print('Loading data')\n",
        "    \n",
        "  X = []\n",
        "  y = []\n",
        "\n",
        "  for filename in data_list:\n",
        "    data_l = loadmat(filename)\n",
        "    data = data_l['data']\n",
        "    d = resample(data, 256, axis=1)\n",
        "    c = (d-d.mean())/d.std()\n",
        "    X.append(c)\n",
        "    y.append(y_value)\n",
        "      \n",
        "  X = np.array(X)\n",
        "  y = np.array(y)\n",
        "\n",
        "  return X,y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDQ2IZ1TYYvs",
        "colab_type": "text"
      },
      "source": [
        "# Split data set in train and test\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-10LpmhGXXnC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_split_data(ictal_list, interictal_list):\n",
        "\n",
        "  X_ictal, y_ictal = parse_input_data(ictal_list, 'ictal')\n",
        "  X_interictal, y_interictal = parse_input_data(interictal_list, 'interictal')\n",
        "\n",
        "  X = np.concatenate((X_ictal, X_interictal), axis=0)\n",
        "  y = np.concatenate((y_ictal, y_interictal), axis=0)\n",
        "  X = np.swapaxes(X,1,2)\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "\n",
        "  return X_train, X_test, y_train, y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NWCuFCpYoJv",
        "colab_type": "text"
      },
      "source": [
        "# Over sampling the data to fix unbalanced dataset\n",
        "\n",
        "finally it wasn't used for training because it didn´t show an improvement"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pJNBsJ9YCLV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def over_saple_train(X_train, y_train):\n",
        "\n",
        "  for i in range(X_train.shape[2]):\n",
        "    sm = SMOTE(random_state=42)\n",
        "    X_c = X_train[:,:,i]\n",
        "    X_res, y_res = sm.fit_resample(X_c, y_train)\n",
        "    X_res = X_res.reshape(-1,X_res.shape[1],1)\n",
        "  \n",
        "    if i ==0:\n",
        "      X_s =  X_res\n",
        "    else:\n",
        "      X_s = np.concatenate((X_s, X_res), axis=2)\n",
        "  return X_s, y_res\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jvA7LgzZGDt",
        "colab_type": "text"
      },
      "source": [
        "# For each subject a model with the same configuration was trained\n",
        "\n",
        "1.   2 layers of LSTM with 128 cell each one\n",
        "2.   1 dropout layer\n",
        "3.   1 fully connected layer for classification output \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTJ4EJODZFXI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(X_train, y_train,X_test, y_test):\n",
        "  \n",
        "  early_stop = EarlyStopping(monitor='val_accuracy',\n",
        "                                           min_delta=0,\n",
        "                                           patience=10,\n",
        "                                           verbose=1,\n",
        "                                           mode='auto')\n",
        "  n_batch = 1\n",
        "  epochs = 100\n",
        "\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(LSTM(128, input_shape=(X_train.shape[1],X_train.shape[2]),return_sequences=True))\n",
        "  model.add(Dropout(rate=0.4))\n",
        "  model.add(LSTM(128))\n",
        "                  \n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "  model.fit(X_train, y_train, batch_size=n_batch, epochs=epochs, verbose=1, validation_data=(X_test, y_test), shuffle=False, callbacks=[early_stop])\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTPyvIrqZE7J",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njIw30ntZaSg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ec337cfd-a0f1-445e-dca5-0f28a59de7ed"
      },
      "source": [
        "subjects = ['Patient_1', 'Patient_3', 'Patient_4', 'Patient_5', 'Patient_6', 'Patient_7', 'Patient_8',\n",
        "            'Dog_1', 'Dog_2', 'Dog_3', 'Dog_4']\n",
        "\n",
        "AUC = []\n",
        "for subject in subjects:\n",
        "\n",
        "  ictal_list, interictal_list = get_data(subject)\n",
        "\n",
        "  X_train, X_test, y_train, y_test = get_split_data(ictal_list, interictal_list)\n",
        "\n",
        "  #X_s, y_res = over_saple_train(X_train, y_train)\n",
        "\n",
        "  model = train_model(X_train, y_train,X_test, y_test)\n",
        "\n",
        "  pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
        "  fpr, tpr, thresholds = metrics.roc_curve(y_test, pred)\n",
        "  auc = metrics.auc(fpr, tpr)\n",
        "  AUC.append(auc)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading data\n",
            "Loading data\n",
            "Epoch 1/100\n",
            "139/139 [==============================] - 23s 167ms/step - loss: 0.7071 - accuracy: 0.5324 - val_loss: 0.5738 - val_accuracy: 0.7143\n",
            "Epoch 2/100\n",
            "139/139 [==============================] - 22s 161ms/step - loss: 0.2968 - accuracy: 0.8993 - val_loss: 0.5054 - val_accuracy: 0.7714\n",
            "Epoch 3/100\n",
            "139/139 [==============================] - 22s 160ms/step - loss: 0.1914 - accuracy: 0.9424 - val_loss: 0.8173 - val_accuracy: 0.6286\n",
            "Epoch 4/100\n",
            "139/139 [==============================] - 23s 166ms/step - loss: 0.1223 - accuracy: 0.9712 - val_loss: 0.9635 - val_accuracy: 0.7143\n",
            "Epoch 5/100\n",
            "139/139 [==============================] - 23s 168ms/step - loss: 0.0730 - accuracy: 0.9784 - val_loss: 0.5657 - val_accuracy: 0.8286\n",
            "Epoch 6/100\n",
            "139/139 [==============================] - 23s 167ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.6948 - val_accuracy: 0.8286\n",
            "Epoch 7/100\n",
            "139/139 [==============================] - 22s 162ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.7450 - val_accuracy: 0.8286\n",
            "Epoch 8/100\n",
            "139/139 [==============================] - 23s 162ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.7812 - val_accuracy: 0.8286\n",
            "Epoch 9/100\n",
            "139/139 [==============================] - 23s 163ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.8128 - val_accuracy: 0.8286\n",
            "Epoch 10/100\n",
            "139/139 [==============================] - 22s 159ms/step - loss: 7.4484e-04 - accuracy: 1.0000 - val_loss: 0.8372 - val_accuracy: 0.8286\n",
            "Epoch 11/100\n",
            "139/139 [==============================] - 29s 207ms/step - loss: 6.2048e-04 - accuracy: 1.0000 - val_loss: 0.8612 - val_accuracy: 0.8286\n",
            "Epoch 12/100\n",
            "139/139 [==============================] - 23s 164ms/step - loss: 4.6040e-04 - accuracy: 1.0000 - val_loss: 0.8751 - val_accuracy: 0.8286\n",
            "Epoch 13/100\n",
            "139/139 [==============================] - 23s 162ms/step - loss: 3.8261e-04 - accuracy: 1.0000 - val_loss: 0.8897 - val_accuracy: 0.8286\n",
            "Epoch 14/100\n",
            "139/139 [==============================] - 23s 163ms/step - loss: 3.1854e-04 - accuracy: 1.0000 - val_loss: 0.9052 - val_accuracy: 0.8286\n",
            "Epoch 15/100\n",
            "139/139 [==============================] - 22s 161ms/step - loss: 2.6066e-04 - accuracy: 1.0000 - val_loss: 0.9173 - val_accuracy: 0.8286\n",
            "Epoch 00015: early stopping\n",
            "Loading data\n",
            "Loading data\n",
            "Epoch 1/100\n",
            "832/832 [==============================] - 132s 159ms/step - loss: 0.6406 - accuracy: 0.6647 - val_loss: 0.6459 - val_accuracy: 0.6507\n",
            "Epoch 2/100\n",
            "832/832 [==============================] - 128s 154ms/step - loss: 0.6045 - accuracy: 0.7007 - val_loss: 0.6148 - val_accuracy: 0.7033\n",
            "Epoch 3/100\n",
            "832/832 [==============================] - 127s 153ms/step - loss: 0.5506 - accuracy: 0.7428 - val_loss: 0.5789 - val_accuracy: 0.6938\n",
            "Epoch 4/100\n",
            "832/832 [==============================] - 128s 154ms/step - loss: 0.4693 - accuracy: 0.7873 - val_loss: 0.5431 - val_accuracy: 0.7177\n",
            "Epoch 5/100\n",
            "832/832 [==============================] - 129s 155ms/step - loss: 0.3848 - accuracy: 0.8329 - val_loss: 0.3904 - val_accuracy: 0.8182\n",
            "Epoch 6/100\n",
            "832/832 [==============================] - 130s 156ms/step - loss: 0.2777 - accuracy: 0.8906 - val_loss: 0.4632 - val_accuracy: 0.7799\n",
            "Epoch 7/100\n",
            "832/832 [==============================] - 129s 155ms/step - loss: 0.1762 - accuracy: 0.9327 - val_loss: 0.5286 - val_accuracy: 0.8182\n",
            "Epoch 8/100\n",
            "832/832 [==============================] - 125s 150ms/step - loss: 0.2233 - accuracy: 0.9147 - val_loss: 0.5751 - val_accuracy: 0.7990\n",
            "Epoch 9/100\n",
            "832/832 [==============================] - 124s 149ms/step - loss: 0.1804 - accuracy: 0.9363 - val_loss: 0.5126 - val_accuracy: 0.8182\n",
            "Epoch 10/100\n",
            "832/832 [==============================] - 123s 148ms/step - loss: 0.1392 - accuracy: 0.9519 - val_loss: 0.5782 - val_accuracy: 0.7943\n",
            "Epoch 11/100\n",
            "832/832 [==============================] - 124s 149ms/step - loss: 0.1126 - accuracy: 0.9651 - val_loss: 0.5418 - val_accuracy: 0.8230\n",
            "Epoch 12/100\n",
            "832/832 [==============================] - 121s 145ms/step - loss: 0.1260 - accuracy: 0.9507 - val_loss: 0.4855 - val_accuracy: 0.8373\n",
            "Epoch 13/100\n",
            "832/832 [==============================] - 124s 149ms/step - loss: 0.0333 - accuracy: 0.9892 - val_loss: 0.7354 - val_accuracy: 0.8134\n",
            "Epoch 14/100\n",
            "832/832 [==============================] - 123s 148ms/step - loss: 0.0432 - accuracy: 0.9892 - val_loss: 0.8635 - val_accuracy: 0.8230\n",
            "Epoch 15/100\n",
            "832/832 [==============================] - 124s 150ms/step - loss: 0.0572 - accuracy: 0.9832 - val_loss: 0.6537 - val_accuracy: 0.8134\n",
            "Epoch 16/100\n",
            "832/832 [==============================] - 125s 150ms/step - loss: 0.0790 - accuracy: 0.9724 - val_loss: 0.6621 - val_accuracy: 0.8182\n",
            "Epoch 17/100\n",
            "832/832 [==============================] - 123s 148ms/step - loss: 0.0623 - accuracy: 0.9796 - val_loss: 0.7139 - val_accuracy: 0.7990\n",
            "Epoch 18/100\n",
            "832/832 [==============================] - 124s 150ms/step - loss: 0.1291 - accuracy: 0.9639 - val_loss: 0.7314 - val_accuracy: 0.7943\n",
            "Epoch 19/100\n",
            "832/832 [==============================] - 125s 150ms/step - loss: 0.0895 - accuracy: 0.9724 - val_loss: 0.7442 - val_accuracy: 0.8038\n",
            "Epoch 20/100\n",
            "832/832 [==============================] - 125s 150ms/step - loss: 0.0381 - accuracy: 0.9880 - val_loss: 0.8772 - val_accuracy: 0.8278\n",
            "Epoch 21/100\n",
            "832/832 [==============================] - 127s 152ms/step - loss: 0.0527 - accuracy: 0.9856 - val_loss: 0.7749 - val_accuracy: 0.8182\n",
            "Epoch 22/100\n",
            "253/832 [========>.....................] - ETA: 1:23 - loss: 0.0515 - accuracy: 0.9763"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WLKj20Kaakq",
        "colab_type": "text"
      },
      "source": [
        "# Comparision with kaggle competition leaderBoard:\n",
        "\n",
        "The winner got a value for mean AUC of **0.96287**\n",
        "\n",
        "He used:\n",
        "\n",
        "* Combination of  FFT with time and frequency correlation, taking both correlation coefficients and eigenvalues\n",
        "* RandomForestClassifier\n",
        "\n",
        "https://github.com/MichaelHills/seizure-detection"
      ]
    }
  ]
}